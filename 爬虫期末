豆瓣top250电视剧
from urllib.request import urlopen, Request
from bs4 import BeautifulSoup
import re
import xlwt
import time
import os
import random
workbook = xlwt.Workbook(encoding='UTF-8')
worksheet = workbook.add_sheet('drama',cell_overwrite_ok=True)
worksheet.write(0, 0, label="电视剧名称")
worksheet.write(0, 1, label="导演")
worksheet.write(0, 2, label="主演")
worksheet.write(0, 3, label="类型")
worksheet.write(0, 4, label="地区")
worksheet.write(0, 5, label="年份")
worksheet.write(0, 6, label="评分")
count = 1
for i in range(0,4):

    url="https://www.douban.com/doulist/44811565/?start={}&sort=seq&playable=0&sub_type=".format(i*25)
    headers={'User-Agent':'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/69.0.3947.100 Safari/537.36'}
    ret=Request(url,headers=headers)
    html=urlopen(ret)
    bs=BeautifulSoup(html,"html.parser")
    item = bs.find_all('div', {"class":"bd doulist-subject"})
    for items in item:
        title=items.find('div',{"class":"title"}).text
        alls = items.find('div',{"class":"abstract"}).text
        all = alls.split(':',5)
        ss=items.find('span',{"class":"rating_nums"}).text
        # print(title,alls,ss)
        worksheet.write(count, 0, title)
        worksheet.write(count, 1, all[1])
        worksheet.write(count, 2, all[2])
        worksheet.write(count, 3, all[3])
        worksheet.write(count, 4, all[4])
        worksheet.write(count, 5, all[5])
        worksheet.write(count, 6, ss)
        count += 1
        workbook.save('1.xls'))
 -----------------------------------------------------------------------------------------------------------------------------       
豆瓣top250音乐
from urllib.request import urlopen, Request
from bs4 import BeautifulSoup
import xlwt

workbook = xlwt.Workbook(encoding='UTF-8')
worksheet = workbook.add_sheet('music',cell_overwrite_ok=True)
worksheet.write(0, 0, label="歌名")
worksheet.write(0, 1, label="歌手")
worksheet.write(0, 2, label="时间")
worksheet.write(0, 3, label="类型")
worksheet.write(0, 4, label="风格")
worksheet.write(0, 5, label="评分")
# worksheet.write(0, 6, label="评语")
count = 1
for i in range(0,10):

    url="https://music.douban.com/top250?start={}".format(i*25)
    headers={'User-Agent':'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/69.0.3947.100 Safari/537.36'}
    ret=Request(url,headers=headers)
    html=urlopen(ret)
    bs=BeautifulSoup(html,"html.parser")
    item = bs.find_all('table',{"width":"100%%"})
    for items in item:
        try:
            title=items.find('a',{"class":"nbg"}).get("title")
            t = title.split('-',3)
            alls = items.find('p',{"class":"pl"}).text
            all = alls.rsplit(' / ',5)
            ss=items.find('span',{"class":"rating_nums"}).text
        # print(all[4])
            worksheet.write(count, 0, t[1])
            worksheet.write(count, 1, all[0])
            worksheet.write(count, 2, all[1])
            worksheet.write(count, 5, ss)
            worksheet.write(count, 3, all[2])
            worksheet.write(count, 4, all[4])
            count += 1
            workbook.save('2.xls')
        except:
            continue
#豆瓣top250图书
import re
import xlwt
import requests
from bs4 import BeautifulSoup


def getHtml(url):
    headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:56.0) Gecko/20100101 Firefox/56.0'}
    page = requests.get(url, headers=headers)
    html = page.text
    return html


if __name__ == '__main__':
    Workbook = xlwt.Workbook()
    sheet = Workbook.add_sheet('豆瓣图书Top250')
    sheet.write(2, 2, '书名')
    sheet.write(2, 3, '作者')
    sheet.write(2, 4, '译者')
    sheet.write(2, 5, '出版单位')
    sheet.write(2, 6, '出版时间')
    sheet.write(2, 7, '定价')
    sheet.write(2, 8, '豆瓣评分')
    sheet.write(2, 9, '评价人数')
    sheet.write(2, 10, '短评')

    i = 3
    j = 3
    k = 3
    m = 3
    for page in range(0, 250, 25):
        url = 'https://book.douban.com/top250?start={0}'.format(page)
        html = getHtml(url)
        Soup = BeautifulSoup(html, 'html.parser')
        names = Soup.find_all('div', class_='pl2')

        # for name in names:
        #     book = name.find('a')
        #     book = book.text.strip()
        #     book = book.replace(' ', '')
        #     sheet.write(i, 2, book)
        #     i += 1

        Infos = Soup.find_all('p', class_='pl')
        for Info in Infos:
            r = 1
            authorinfo = Info.text
            authors = authorinfo.split('/')
            if len(authors) < 4:
                sheet.write(j, 5, authors[0])
                sheet.write(j, 6, authors[1])
                sheet.write(j, 7, authors[2])
                j += 1
                continue
            sheet.write(j, 3, authors[0])
            if authorinfo.count('/') == 4:
                sheet.write(j, 4, authors[r])
                r += 1
            sheet.write(j, 5, authors[r])
            sheet.write(j, 6, authors[r + 1])
            sheet.write(j, 7, authors[r + 2])
            j += 1

        # rating_nums = Soup.find_all('div', class_='star clearfix')
        # for rating in rating_nums:
        #     star = rating.find_all('span')
        #     sheet.write(k, 8, star[1].text)
        #     reg = r'\d+'
        #     vote = re.findall(reg, star[2].text)
        #     sheet.write(k, 9, vote)
        #     k += 1
        # quotes = Soup.find_all('p', class_='quote')
        # for quote in quotes:
        #     sheet.write(m, 10, quote.text)
        #     m += 1

    Workbook.save('豆瓣图书Top250.xls')
